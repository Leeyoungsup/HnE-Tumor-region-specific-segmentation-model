{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "intro-md",
   "metadata": {},
   "source": [
    "# Stomach WSI Segmentation Prediction\n",
    "\n",
    "Whole Slide Image segmentation using **Overlapping Patch + Weighted Blending** approach.\n",
    "\n",
    "- Model trained at 1.0 mpp\n",
    "- Output mask at 8.0 mpp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "imports",
   "metadata": {},
   "outputs": [],
   "source": [
    "import openslide\n",
    "import os\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from glob import glob\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import segmentation_models_pytorch as smp\n",
    "from torchvision.transforms import ToTensor\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "config",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration\n",
    "wsi_list = glob('../../data/IHC_HE_Pair_Data_GA_SS/PD-L1(HnE)/*.ndpi')\n",
    "model_mpp = 0.9188          # Model was trained at this MPP\n",
    "output_mpp = 4.0         # Output mask resolution\n",
    "image_size = 512         # Patch size for model input\n",
    "overlap_ratio = 0.7      # 70% overlap between patches\n",
    "batch_size = 8           # Batch size for inference\n",
    "\n",
    "# Class configuration\n",
    "class_list = [\n",
    "    \"Background\",\n",
    "    \"Stroma\",\n",
    "    \"Non_Tumor\",\n",
    "    \"Tumor\",\n",
    "]\n",
    "num_classes = len(class_list)\n",
    "\n",
    "# Color map for visualization\n",
    "color_map = {\n",
    "    0: (255, 255, 255),  # Background - White\n",
    "    1: (0, 255, 0),      # Stroma - Green\n",
    "    2: (0, 0, 255),      # Non_Tumor - Blue\n",
    "    3: (255, 255, 0),    # Tumor - Yellow\n",
    "}\n",
    "\n",
    "# Device\n",
    "device = torch.device(\"cuda:1\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "print(f\"Number of WSIs: {len(wsi_list)}\")\n",
    "print(f\"Model MPP: {model_mpp}, Output MPP: {output_mpp}\")\n",
    "print(f\"Image size: {image_size}, Overlap ratio: {overlap_ratio}, Batch size: {batch_size}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "load-model",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load trained model\n",
    "model_path = '../../model/Tumor_region_segmentation/stomach/ST_callback.pt'\n",
    "\n",
    "model = smp.DeepLabV3Plus(\n",
    "    encoder_name=\"efficientnet-b5\",\n",
    "    encoder_weights=None,\n",
    "    in_channels=3,\n",
    "    classes=num_classes,\n",
    ").to(device)\n",
    "\n",
    "model.load_state_dict(torch.load(model_path, map_location=device))\n",
    "model.eval()\n",
    "print(f\"Model loaded from: {model_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "weight-mask",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_gaussian_weight_mask(size, sigma=0.25):\n",
    "    \"\"\"\n",
    "    Create a 2D Gaussian weight mask for smooth blending.\n",
    "    Center has higher weight, edges have lower weight.\n",
    "    \"\"\"\n",
    "    x = np.linspace(-1, 1, size)\n",
    "    y = np.linspace(-1, 1, size)\n",
    "    xx, yy = np.meshgrid(x, y)\n",
    "    \n",
    "    # Gaussian distribution\n",
    "    gaussian = np.exp(-(xx**2 + yy**2) / (2 * sigma**2))\n",
    "    \n",
    "    # Normalize to [0, 1]\n",
    "    gaussian = (gaussian - gaussian.min()) / (gaussian.max() - gaussian.min())\n",
    "    \n",
    "    return gaussian.astype(np.float32)\n",
    "\n",
    "def create_linear_weight_mask(size, margin_ratio=0.25):\n",
    "    \"\"\"\n",
    "    Create a linear weight mask that ramps up from edges.\n",
    "    \"\"\"\n",
    "    margin = int(size * margin_ratio)\n",
    "    weight = np.ones((size, size), dtype=np.float32)\n",
    "    \n",
    "    # Create linear ramps for edges\n",
    "    for i in range(margin):\n",
    "        val = (i + 1) / margin\n",
    "        weight[i, :] *= val\n",
    "        weight[-(i+1), :] *= val\n",
    "        weight[:, i] *= val\n",
    "        weight[:, -(i+1)] *= val\n",
    "    \n",
    "    return weight\n",
    "\n",
    "# Create weight mask\n",
    "weight_mask = create_gaussian_weight_mask(image_size, sigma=0.3)\n",
    "\n",
    "# Visualize weight mask\n",
    "plt.figure(figsize=(6, 5))\n",
    "plt.imshow(weight_mask, cmap='hot')\n",
    "plt.colorbar()\n",
    "plt.title('Gaussian Weight Mask for Blending')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "wsi-utils",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_wsi_mpp(slide):\n",
    "    \"\"\"Get MPP (microns per pixel) from WSI metadata.\"\"\"\n",
    "    try:\n",
    "        mpp_x = float(slide.properties.get(openslide.PROPERTY_NAME_MPP_X, 0))\n",
    "        mpp_y = float(slide.properties.get(openslide.PROPERTY_NAME_MPP_Y, 0))\n",
    "        if mpp_x > 0 and mpp_y > 0:\n",
    "            return (mpp_x + mpp_y) / 2\n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "    # Try to get from NDPI specific properties\n",
    "    try:\n",
    "        if 'tiff.XResolution' in slide.properties:\n",
    "            x_res = float(slide.properties['tiff.XResolution'])\n",
    "            # Convert to mpp (assuming resolution is in pixels per cm)\n",
    "            return 10000 / x_res\n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "    # Default assumption for 40x objective\n",
    "    print(\"Warning: Could not determine MPP, using default 0.25\")\n",
    "    return 0.25\n",
    "\n",
    "def find_best_level(slide, target_mpp, base_mpp):\n",
    "    \"\"\"Find the best level to read from based on target MPP.\"\"\"\n",
    "    level_count = slide.level_count\n",
    "    level_downsamples = slide.level_downsamples\n",
    "    \n",
    "    target_downsample = target_mpp / base_mpp\n",
    "    \n",
    "    best_level = 0\n",
    "    best_diff = float('inf')\n",
    "    \n",
    "    for level in range(level_count):\n",
    "        diff = abs(level_downsamples[level] - target_downsample)\n",
    "        if level_downsamples[level] <= target_downsample and diff < best_diff:\n",
    "            best_level = level\n",
    "            best_diff = diff\n",
    "    \n",
    "    return best_level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "prediction-functions",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_wsi_overlapping(slide, model, device, model_mpp, output_mpp, \n",
    "                            patch_size=512, overlap_ratio=0.5, batch_size=8):\n",
    "    \"\"\"\n",
    "    Predict on WSI using overlapping patches with weighted blending.\n",
    "    \n",
    "    Args:\n",
    "        slide: OpenSlide object\n",
    "        model: Trained segmentation model\n",
    "        device: torch device\n",
    "        model_mpp: MPP at which model was trained\n",
    "        output_mpp: Desired output mask MPP\n",
    "        patch_size: Size of patches for model input\n",
    "        overlap_ratio: Overlap ratio between adjacent patches\n",
    "        batch_size: Batch size for inference\n",
    "    \n",
    "    Returns:\n",
    "        prediction_mask: Final prediction mask at output_mpp resolution\n",
    "        thumbnail: WSI thumbnail for visualization\n",
    "    \"\"\"\n",
    "    \n",
    "    # Get WSI properties\n",
    "    base_mpp = get_wsi_mpp(slide)\n",
    "    wsi_w, wsi_h = slide.dimensions\n",
    "    \n",
    "    print(f\"WSI dimensions: {wsi_w} x {wsi_h}\")\n",
    "    print(f\"WSI base MPP: {base_mpp:.4f}\")\n",
    "    \n",
    "    # Calculate scale factors\n",
    "    read_scale = model_mpp / base_mpp  # Scale from base to model resolution\n",
    "    output_scale = output_mpp / model_mpp  # Scale from model to output resolution\n",
    "    \n",
    "    # Patch size at level 0 (base resolution)\n",
    "    patch_size_level0 = int(patch_size * read_scale)\n",
    "    \n",
    "    # Step size with overlap\n",
    "    step_size = int(patch_size * (1 - overlap_ratio))\n",
    "    step_size_level0 = int(step_size * read_scale)\n",
    "    \n",
    "    # Output dimensions at model_mpp resolution\n",
    "    model_res_w = int(wsi_w / read_scale)\n",
    "    model_res_h = int(wsi_h / read_scale)\n",
    "    \n",
    "    # Output dimensions at output_mpp resolution\n",
    "    output_w = int(model_res_w / output_scale)\n",
    "    output_h = int(model_res_h / output_scale)\n",
    "    \n",
    "    print(f\"Model resolution size: {model_res_w} x {model_res_h}\")\n",
    "    print(f\"Output mask size: {output_w} x {output_h}\")\n",
    "    print(f\"Patch size at level 0: {patch_size_level0}\")\n",
    "    print(f\"Step size at level 0: {step_size_level0}\")\n",
    "    \n",
    "    # Find best level for reading\n",
    "    read_level = find_best_level(slide, model_mpp, base_mpp)\n",
    "    level_downsample = slide.level_downsamples[read_level]\n",
    "    actual_read_scale = read_scale / level_downsample\n",
    "    \n",
    "    print(f\"Reading from level {read_level} (downsample: {level_downsample:.2f})\")\n",
    "    \n",
    "    # Initialize accumulators at model resolution\n",
    "    prediction_sum = np.zeros((num_classes, model_res_h, model_res_w), dtype=np.float32)\n",
    "    weight_sum = np.zeros((model_res_h, model_res_w), dtype=np.float32)\n",
    "    \n",
    "    # Create weight mask\n",
    "    weight_mask = create_gaussian_weight_mask(patch_size, sigma=0.3)\n",
    "    \n",
    "    # Calculate number of patches\n",
    "    n_patches_x = max(1, int(np.ceil((wsi_w - patch_size_level0) / step_size_level0)) + 1)\n",
    "    n_patches_y = max(1, int(np.ceil((wsi_h - patch_size_level0) / step_size_level0)) + 1)\n",
    "    total_patches = n_patches_x * n_patches_y\n",
    "    \n",
    "    print(f\"Total patches: {n_patches_x} x {n_patches_y} = {total_patches}\")\n",
    "    \n",
    "    # Generate patch coordinates\n",
    "    patch_coords = []\n",
    "    for y_idx in range(n_patches_y):\n",
    "        for x_idx in range(n_patches_x):\n",
    "            x = min(x_idx * step_size_level0, wsi_w - patch_size_level0)\n",
    "            y = min(y_idx * step_size_level0, wsi_h - patch_size_level0)\n",
    "            x = max(0, x)\n",
    "            y = max(0, y)\n",
    "            patch_coords.append((x, y))\n",
    "    \n",
    "    # Process patches in batches\n",
    "    tf = ToTensor()\n",
    "    \n",
    "    for batch_start in tqdm(range(0, len(patch_coords), batch_size), desc=\"Processing patches\"):\n",
    "        batch_coords = patch_coords[batch_start:batch_start + batch_size]\n",
    "        batch_images = []\n",
    "        valid_coords = []\n",
    "        \n",
    "        for (x, y) in batch_coords:\n",
    "            # Read patch at the best level\n",
    "            try:\n",
    "                patch = slide.read_region(\n",
    "                    (x, y), \n",
    "                    read_level, \n",
    "                    (int(patch_size_level0 / level_downsample), \n",
    "                     int(patch_size_level0 / level_downsample))\n",
    "                ).convert('RGB')\n",
    "                \n",
    "                # Resize to model input size\n",
    "                patch = patch.resize((patch_size, patch_size), Image.BILINEAR)\n",
    "                patch_tensor = tf(patch)\n",
    "                \n",
    "                # Check if patch is mostly background (white)\n",
    "                patch_array = np.array(patch)\n",
    "                white_ratio = np.mean(patch_array > 220)\n",
    "                \n",
    "                if white_ratio < 0.9:  # Skip mostly white patches\n",
    "                    batch_images.append(patch_tensor)\n",
    "                    valid_coords.append((x, y))\n",
    "            except Exception as e:\n",
    "                continue\n",
    "        \n",
    "        if len(batch_images) == 0:\n",
    "            continue\n",
    "        \n",
    "        # Stack and predict\n",
    "        batch_tensor = torch.stack(batch_images).to(device).float()\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            predictions = model(batch_tensor)\n",
    "            predictions = F.softmax(predictions, dim=1)\n",
    "            predictions = predictions.cpu().numpy()\n",
    "        \n",
    "        # Accumulate predictions with weights\n",
    "        for i, (x, y) in enumerate(valid_coords):\n",
    "            # Calculate position in model resolution\n",
    "            x_model = int(x / read_scale)\n",
    "            y_model = int(y / read_scale)\n",
    "            \n",
    "            # Get the region to update\n",
    "            x_end = min(x_model + patch_size, model_res_w)\n",
    "            y_end = min(y_model + patch_size, model_res_h)\n",
    "            \n",
    "            patch_w = x_end - x_model\n",
    "            patch_h = y_end - y_model\n",
    "            \n",
    "            if patch_w <= 0 or patch_h <= 0:\n",
    "                continue\n",
    "            \n",
    "            # Add weighted prediction\n",
    "            for c in range(num_classes):\n",
    "                prediction_sum[c, y_model:y_end, x_model:x_end] += \\\n",
    "                    predictions[i, c, :patch_h, :patch_w] * weight_mask[:patch_h, :patch_w]\n",
    "            \n",
    "            weight_sum[y_model:y_end, x_model:x_end] += weight_mask[:patch_h, :patch_w]\n",
    "    \n",
    "    # Normalize by weights\n",
    "    weight_sum = np.maximum(weight_sum, 1e-6)  # Avoid division by zero\n",
    "    for c in range(num_classes):\n",
    "        prediction_sum[c] /= weight_sum\n",
    "    \n",
    "    # Get final prediction (argmax)\n",
    "    prediction_model_res = np.argmax(prediction_sum, axis=0).astype(np.uint8)\n",
    "    \n",
    "    # Downsample to output resolution\n",
    "    prediction_mask = Image.fromarray(prediction_model_res).resize(\n",
    "        (output_w, output_h), \n",
    "        Image.NEAREST\n",
    "    )\n",
    "    prediction_mask = np.array(prediction_mask)\n",
    "    \n",
    "    # Get thumbnail for visualization\n",
    "    thumbnail = slide.get_thumbnail((output_w, output_h))\n",
    "    thumbnail = np.array(thumbnail.convert('RGB'))\n",
    "    \n",
    "    return prediction_mask, thumbnail, prediction_sum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "colorize-mask",
   "metadata": {},
   "outputs": [],
   "source": [
    "def colorize_mask(mask, color_map):\n",
    "    \"\"\"Convert class mask to RGB image.\"\"\"\n",
    "    h, w = mask.shape\n",
    "    rgb_mask = np.zeros((h, w, 3), dtype=np.uint8)\n",
    "    \n",
    "    for class_idx, color in color_map.items():\n",
    "        rgb_mask[mask == class_idx] = color\n",
    "    \n",
    "    return rgb_mask\n",
    "\n",
    "def create_overlay(image, mask, color_map, alpha=0.4):\n",
    "    \"\"\"Create overlay of mask on image.\"\"\"\n",
    "    overlay = image.copy()\n",
    "    \n",
    "    for class_idx, color in color_map.items():\n",
    "        if class_idx == 0:  # Skip background\n",
    "            continue\n",
    "        mask_area = (mask == class_idx)\n",
    "        if mask_area.any():\n",
    "            color_array = np.array(color, dtype=np.uint8)\n",
    "            overlay[mask_area] = ((1 - alpha) * overlay[mask_area] + alpha * color_array).astype(np.uint8)\n",
    "    \n",
    "    return overlay"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "process-md",
   "metadata": {},
   "source": [
    "## Process First WSI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "process-first-wsi",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process first WSI\n",
    "wsi_path = wsi_list[1]\n",
    "print(f\"Processing: {os.path.basename(wsi_path)}\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Open slide\n",
    "slide = openslide.OpenSlide(wsi_path)\n",
    "\n",
    "# Print slide info\n",
    "print(f\"Dimensions: {slide.dimensions}\")\n",
    "print(f\"Level count: {slide.level_count}\")\n",
    "print(f\"Level dimensions: {slide.level_dimensions}\")\n",
    "print(f\"Level downsamples: {slide.level_downsamples}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "run-prediction",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run prediction\n",
    "prediction_mask, thumbnail, prob_maps = predict_wsi_overlapping(\n",
    "    slide=slide,\n",
    "    model=model,\n",
    "    device=device,\n",
    "    model_mpp=model_mpp,\n",
    "    output_mpp=output_mpp,\n",
    "    patch_size=image_size,\n",
    "    overlap_ratio=overlap_ratio,\n",
    "    batch_size=batch_size\n",
    ")\n",
    "\n",
    "print(f\"\\nPrediction mask shape: {prediction_mask.shape}\")\n",
    "print(f\"Thumbnail shape: {thumbnail.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "visualize-results",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize results\n",
    "fig, axes = plt.subplots(2, 2, figsize=(20, 20))\n",
    "\n",
    "# Original thumbnail\n",
    "axes[0, 0].imshow(thumbnail)\n",
    "axes[0, 0].set_title(f'Original WSI Thumbnail\\n({thumbnail.shape[1]}x{thumbnail.shape[0]} @ {output_mpp} mpp)', fontsize=14)\n",
    "axes[0, 0].axis('off')\n",
    "\n",
    "# Prediction mask (colorized)\n",
    "colored_mask = colorize_mask(prediction_mask, color_map)\n",
    "axes[0, 1].imshow(colored_mask)\n",
    "axes[0, 1].set_title('Prediction Mask (Colorized)', fontsize=14)\n",
    "axes[0, 1].axis('off')\n",
    "\n",
    "# Overlay\n",
    "overlay = create_overlay(thumbnail, prediction_mask, color_map, alpha=0.5)\n",
    "axes[1, 0].imshow(overlay)\n",
    "axes[1, 0].set_title('Overlay (Original + Prediction)', fontsize=14)\n",
    "axes[1, 0].axis('off')\n",
    "\n",
    "# Class distribution\n",
    "unique, counts = np.unique(prediction_mask, return_counts=True)\n",
    "class_counts = {class_list[i]: counts[list(unique).index(i)] if i in unique else 0 \n",
    "                for i in range(num_classes)}\n",
    "total_pixels = prediction_mask.size\n",
    "\n",
    "colors = [np.array(color_map[i])/255.0 for i in range(num_classes)]\n",
    "bars = axes[1, 1].bar(class_list, [class_counts[c] for c in class_list], color=colors, edgecolor='black')\n",
    "axes[1, 1].set_ylabel('Pixel Count')\n",
    "axes[1, 1].set_title('Class Distribution', fontsize=14)\n",
    "axes[1, 1].tick_params(axis='x', rotation=45)\n",
    "\n",
    "# Add percentage labels\n",
    "for bar, count in zip(bars, [class_counts[c] for c in class_list]):\n",
    "    percentage = 100 * count / total_pixels\n",
    "    axes[1, 1].text(bar.get_x() + bar.get_width()/2, bar.get_height(), \n",
    "                    f'{percentage:.1f}%', ha='center', va='bottom', fontsize=10)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "show-legend",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show color legend\n",
    "fig, ax = plt.subplots(figsize=(10, 2))\n",
    "for i, (class_idx, color) in enumerate(color_map.items()):\n",
    "    ax.barh(0, 1, left=i, color=np.array(color)/255.0, edgecolor='black', linewidth=2)\n",
    "    ax.text(i+0.5, 0, class_list[class_idx], ha='center', va='center', \n",
    "            fontsize=12, fontweight='bold')\n",
    "\n",
    "ax.set_xlim(0, len(color_map))\n",
    "ax.set_ylim(-0.5, 0.5)\n",
    "ax.set_title('Class Color Legend', fontsize=14)\n",
    "ax.axis('off')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "probability-maps",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize probability maps for each class\n",
    "fig, axes = plt.subplots(1, num_classes, figsize=(20, 5))\n",
    "\n",
    "# Downsample probability maps to output resolution\n",
    "for c in range(num_classes):\n",
    "    prob_map_resized = Image.fromarray(prob_maps[c]).resize(\n",
    "        (prediction_mask.shape[1], prediction_mask.shape[0]), \n",
    "        Image.BILINEAR\n",
    "    )\n",
    "    prob_map_resized = np.array(prob_map_resized)\n",
    "    \n",
    "    im = axes[c].imshow(prob_map_resized, cmap='hot', vmin=0, vmax=1)\n",
    "    axes[c].set_title(f'{class_list[c]}\\nProbability Map', fontsize=12)\n",
    "    axes[c].axis('off')\n",
    "    plt.colorbar(im, ax=axes[c], fraction=0.046, pad=0.04)\n",
    "\n",
    "plt.suptitle('Class Probability Maps', fontsize=14, y=1.02)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "save-results",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save results (optional)\n",
    "output_dir = '../../results/wsi_predictions/stomach/'\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "wsi_name = os.path.splitext(os.path.basename(wsi_path))[0]\n",
    "\n",
    "# Save prediction mask\n",
    "np.save(f'{output_dir}{wsi_name}_mask.npy', prediction_mask)\n",
    "\n",
    "# Save colored mask as image\n",
    "Image.fromarray(colored_mask).save(f'{output_dir}{wsi_name}_colored_mask.png')\n",
    "\n",
    "# Save overlay\n",
    "Image.fromarray(overlay).save(f'{output_dir}{wsi_name}_overlay.png')\n",
    "\n",
    "print(f\"Results saved to: {output_dir}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "close-slide",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Close slide\n",
    "slide.close()\n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "summary-md",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "This notebook performs WSI segmentation using:\n",
    "\n",
    "1. **Overlapping Patches**: 50% overlap to ensure smooth predictions across patch boundaries\n",
    "2. **Weighted Blending**: Gaussian weight mask gives higher weight to patch centers, lower weight to edges\n",
    "3. **Multi-scale Processing**: Reads at optimal level, processes at model resolution (1.0 mpp), outputs at 8.0 mpp\n",
    "\n",
    "### Output\n",
    "- Prediction mask at 8.0 mpp resolution\n",
    "- Colored visualization\n",
    "- Overlay on original thumbnail\n",
    "- Class probability maps"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
